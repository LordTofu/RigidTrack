\hypertarget{main_8h}{}\section{Rigid\+Track/main.h File Reference}
\label{main_8h}\index{Rigid\+Track/main.\+h@{Rigid\+Track/main.\+h}}
{\ttfamily \#include $<$fstream$>$}\newline
{\ttfamily \#include $<$windows.\+h$>$}\newline
{\ttfamily \#include $<$conio.\+h$>$}\newline
{\ttfamily \#include $<$tchar.\+h$>$}\newline
{\ttfamily \#include $<$stdio.\+h$>$}\newline
{\ttfamily \#include $<$iostream$>$}\newline
{\ttfamily \#include $<$stdarg.\+h$>$}\newline
{\ttfamily \#include $<$ctype.\+h$>$}\newline
{\ttfamily \#include $<$stdlib.\+h$>$}\newline
{\ttfamily \#include $<$gl/glu.\+h$>$}\newline
{\ttfamily \#include $<$sstream$>$}\newline
{\ttfamily \#include $<$thread$>$}\newline
{\ttfamily \#include $<$future$>$}\newline
{\ttfamily \#include $<$atomic$>$}\newline
{\ttfamily \#include \char`\"{}communication.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}Rigid\+Track.\+h\char`\"{}}\newline
{\ttfamily \#include $<$Qt\+Widgets/\+Q\+Application$>$}\newline
{\ttfamily \#include $<$Q\+Udp\+Socket$>$}\newline
{\ttfamily \#include \char`\"{}cameralibrary.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}modulevector.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}modulevectorprocessing.\+h\char`\"{}}\newline
{\ttfamily \#include \char`\"{}coremath.\+h\char`\"{}}\newline
{\ttfamily \#include $<$opencv\textbackslash{}cv.\+h$>$}\newline
{\ttfamily \#include \char`\"{}opencv2\textbackslash{}core.\+hpp\char`\"{}}\newline
{\ttfamily \#include \char`\"{}opencv2\textbackslash{}calib3d.\+hpp\char`\"{}}\newline
{\ttfamily \#include $<$opencv2/imgproc/imgproc.\+hpp$>$}\newline
{\ttfamily \#include $<$opencv2/calib3d/calib3d.\+hpp$>$}\newline
{\ttfamily \#include $<$opencv2/highgui/highgui.\+hpp$>$}\newline
{\ttfamily \#include $<$opencv2\textbackslash{}video\textbackslash{}tracking.\+hpp$>$}\newline
Include dependency graph for main.\+h\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h__incl}
\end{center}
\end{figure}
This graph shows which files directly or indirectly include this file\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h__dep__incl}
\end{center}
\end{figure}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
int \hyperlink{main_8h_a3d3afd29ce54eb7fc5cc7e74ab666586}{start\+Tracking} ()
\item 
void \hyperlink{main_8h_a25183e8d0b386ef12b557efc712a0261}{start\+Stop\+Camera} ()
\begin{DoxyCompactList}\small\item\em Start or stop the tracking depending on if the camera is currently running or not. \end{DoxyCompactList}\item 
int \hyperlink{main_8h_a1e6662e0f16887fe97c7bebe05065972}{set\+Reference} ()
\item 
int \hyperlink{main_8h_a5f7c5996cd5a271d0277e0741f73a5b4}{calibrate\+Camera} ()
\begin{DoxyCompactList}\small\item\em Start the camera calibration routine that computes the camera matrix and distortion coefficients. \end{DoxyCompactList}\item 
void \hyperlink{main_8h_ad39626702ff983d5fdab4b703bfaf964}{load\+Calibration} (int method)
\item 
void \hyperlink{main_8h_a847c0fbd3e513fb76ff145b31a9f5c37}{test\+Algorithms} ()
\item 
void \hyperlink{main_8h_a2104a5d9d6b9f1e29bc4cd858c59882e}{project\+Coordinate\+Frame} (Mat picture\+Frame)
\item 
void \hyperlink{main_8h_ae624b0189bc5e32cbbb1f178b9f1a360}{set\+Up\+U\+DP} ()
\begin{DoxyCompactList}\small\item\em Open the U\+DP ports for communication. \end{DoxyCompactList}\item 
void \hyperlink{main_8h_ad19da4e648bbdc80d3123eb94711588e}{set\+Heading\+Offset} (double d)
\item 
void \hyperlink{main_8h_a54b6b6db348b48d21e1265e22829c61f}{send\+Data\+U\+DP} (cv\+::\+Vec3d \&Position, cv\+::\+Vec3d \&Euler)
\item 
void \hyperlink{main_8h_af2a8b7de0b15dc17198c147ba39e85f3}{close\+U\+DP} ()
\item 
void \hyperlink{main_8h_a56c7f641859cb2b6b99b0947d03be800}{load\+Marker\+Config} (int method)
\item 
void \hyperlink{main_8h_af6430ad2592a955a3618549547dfc5be}{draw\+Position\+Text} (cv\+::\+Mat \&Picture, cv\+::\+Vec3d \&Position, cv\+::\+Vec3d \&Euler, double \hyperlink{_import_log_8m_af10dacfa214e2575bb2e0ee407c242e0}{error})
\item 
void \hyperlink{main_8h_af39fa6c3a36ad6bc24a327db7a9d73c2}{load\+Camera\+Position} ()
\item 
int \hyperlink{main_8h_a0416912fce6274568e80019b10ba294f}{determine\+Exposure} ()
\item 
void \hyperlink{main_8h_a11ff459289305229597defd39f510959}{determine\+Order} ()
\item 
int \hyperlink{main_8h_a7ad2e3cfb5056dbab2098e0dd3bd353f}{calibrate\+Ground} ()
\end{DoxyCompactItemize}
\subsection*{Variables}
\begin{DoxyCompactItemize}
\item 
int \hyperlink{main_8h_ab5e634b66221f494504aea1557af5df9}{method\+P\+NP}
\begin{DoxyCompactList}\small\item\em solve\+P\+NP algorithm 0 = iterative 1 = E\+P\+NP 2 = P3P 4 = U\+P\+NP //!$<$ 4 and 1 are the same and not implemented correctly by Open\+CV \end{DoxyCompactList}\item 
bool \hyperlink{main_8h_aa6266eedab8b3c011be53baffbfc42ab}{safety\+Enable}
\begin{DoxyCompactList}\small\item\em is the safety feature enabled \end{DoxyCompactList}\item 
bool \hyperlink{main_8h_a436fb814ccc3f02617dade4dc6511143}{safety2\+Enable}
\begin{DoxyCompactList}\small\item\em is the second receiver enabled \end{DoxyCompactList}\item 
double \hyperlink{main_8h_a2c1b807fcb2de5a6759bd60ccae6dd7e}{safety\+Box\+Length}
\begin{DoxyCompactList}\small\item\em length of the safety area cube in meters \end{DoxyCompactList}\item 
int \hyperlink{main_8h_ae65386c3310ab826e84fba757296de9a}{safety\+Angle}
\begin{DoxyCompactList}\small\item\em bank and pitch angle protection in degrees \end{DoxyCompactList}\item 
Q\+Host\+Address \hyperlink{main_8h_ab97ac0d82b1753d0eef37089be17e5e1}{I\+P\+Adress\+Object}
\begin{DoxyCompactList}\small\item\em I\+Pv4 adress of receiver 1. \end{DoxyCompactList}\item 
Q\+Host\+Address \hyperlink{main_8h_afefb1102a8a4a71b55d6f24f46404cc5}{I\+P\+Adress\+Safety}
\begin{DoxyCompactList}\small\item\em I\+Pv4 adress of safety receiver. \end{DoxyCompactList}\item 
Q\+Host\+Address \hyperlink{main_8h_a354806cf8cbface3575f2541d8fbcbda}{I\+P\+Adress\+Safety2}
\begin{DoxyCompactList}\small\item\em I\+Pv4 adress of receiver 2. \end{DoxyCompactList}\item 
int \hyperlink{main_8h_a9a00043c93a3362969c1c1fcd3a70fea}{port\+Object}
\begin{DoxyCompactList}\small\item\em Port of receiver 1. \end{DoxyCompactList}\item 
int \hyperlink{main_8h_a137bc8cc9d53ad9b176c988a99bc7142}{port\+Safety}
\begin{DoxyCompactList}\small\item\em Port of the safety receiver. \end{DoxyCompactList}\item 
int \hyperlink{main_8h_a2601be9c226be24c71ec8282f632e723}{port\+Safety2}
\begin{DoxyCompactList}\small\item\em Port of receiver 2. \end{DoxyCompactList}\item 
int \hyperlink{main_8h_a5cc3bd09f5801804b7ae65846e0b9824}{invertZ}
\begin{DoxyCompactList}\small\item\em dummy variable to invert Z direction on request \end{DoxyCompactList}\item 
\hyperlink{classcomm_object}{comm\+Object} \hyperlink{main_8h_af29e7fc07ae0979d5fb61b473241d33d}{comm\+Obj}
\begin{DoxyCompactList}\small\item\em class that handles the communication from \hyperlink{main_8cpp}{main.\+cpp} to the G\+UI \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Function Documentation}
\mbox{\Hypertarget{main_8h_a5f7c5996cd5a271d0277e0741f73a5b4}\label{main_8h_a5f7c5996cd5a271d0277e0741f73a5b4}} 
\index{main.\+h@{main.\+h}!calibrate\+Camera@{calibrate\+Camera}}
\index{calibrate\+Camera@{calibrate\+Camera}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{calibrate\+Camera()}{calibrateCamera()}}
{\footnotesize\ttfamily int calibrate\+Camera (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Start the camera calibration routine that computes the camera matrix and distortion coefficients. 

Initialize Camera S\+DK ==--

At this point the Camera S\+DK is actively looking for all connected cameras and will initialize them on it\textquotesingle{}s own.

Get a connected camera ================-\/---

Determine camera resolution

Set Video Mode ==--

We set the camera to Segment Mode here. This mode is support by all of our products. Depending on what device you have connected you might want to consider a different video mode to achieve the best possible tracking quality. All devices that support a mode that will achieve a better quality output with a mode other than Segment Mode are listed here along with what mode you should use if you\textquotesingle{}re looking for the best head tracking\+: \begin{DoxyVerb}V100:R1/R2    Precision Mode
TrackIR 5     Bit-Packed Precision Mode
V120          Precision Mode
TBar          Precision Mode
S250e         Precision Mode
\end{DoxyVerb}


If you have questions about a new device that might be conspicuously missing here or have any questions about head tracking, email support or participate in our forums.

Start camera output ==--

Camera Matrix creation ==--

Ok, start main loop. This loop fetches and displays ===--- camera frames. ===--- But first set some camera parameters

the user has to provide the size of one square in mm

Fetch a new frame from the camera ===---

which is why we also set this constant to 8

later on, when we get the frame as usual\+:

Lets have the Camera Library raster the camera\textquotesingle{}s image into our texture.

$<$ If done with success,

improve the found corners\textquotesingle{} coordinate accuracy for chessboard

Release camera ==--

Save the obtained calibration coefficients in a file for later use Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a5f7c5996cd5a271d0277e0741f73a5b4_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=339pt]{main_8h_a5f7c5996cd5a271d0277e0741f73a5b4_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a7ad2e3cfb5056dbab2098e0dd3bd353f}\label{main_8h_a7ad2e3cfb5056dbab2098e0dd3bd353f}} 
\index{main.\+h@{main.\+h}!calibrate\+Ground@{calibrate\+Ground}}
\index{calibrate\+Ground@{calibrate\+Ground}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{calibrate\+Ground()}{calibrateGround()}}
{\footnotesize\ttfamily int calibrate\+Ground (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Get the pose of the camera w.\+r.\+t the ground calibration frame. This frame sets the navigation frame for later results. The pose is averaged over 200 samples and then saved in the file reference\+Data.\+xml. This routine is basically the same as set\+Reference. initialize the variables with starting values

Initialize Camera S\+DK ==--

At this point the Camera S\+DK is actively looking for all connected cameras and will initialize them on it\textquotesingle{}s own.

Get a connected camera ================-\/---

If no device connected, pop a message box and exit ==--

Determine camera resolution to size application window ==-\/---

Set camera mode to precision mode, it directly provides marker coordinates

Start camera output ==--

Turn on some overlay text so it\textquotesingle{}s clear things are ===--- working even if there is nothing in the camera\textquotesingle{}s view. ===--- Set some other parameters as well of the camera

sample some frames and calculate the position and attitude. then average those values and use that as zero position

Fetch a new frame from the camera ===---

Ok, we\textquotesingle{}ve received a new frame, lets do something with it.

for(int i=0; i$<$frame-\/$>$Object\+Count(); i++)

sort the 2d points with the correct indices as found in the preceeding order determination algorithm

Compute the pose from the 3\+D-\/2D corresponses

project the marker 3d points with the solution into the camera image Co\+Sy and calculate difference to true camera image

$<$Iterative Method needs time to converge to solution

$<$ That are not the values of yaw, roll and pitch yet! Rodriguez has to be called first.

$<$-- one sample more \+:D

Release camera ==--

Divide by the number of samples to get the mean of the reference position

$<$ euler\+Ref is here in Axis Angle notation

$<$ axis angle to rotation matrix

$<$ rotation matrix to euler

Save the obtained calibration coefficients in a file for later use Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a7ad2e3cfb5056dbab2098e0dd3bd353f_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=337pt]{main_8h_a7ad2e3cfb5056dbab2098e0dd3bd353f_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_af2a8b7de0b15dc17198c147ba39e85f3}\label{main_8h_af2a8b7de0b15dc17198c147ba39e85f3}} 
\index{main.\+h@{main.\+h}!close\+U\+DP@{close\+U\+DP}}
\index{close\+U\+DP@{close\+U\+DP}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{close\+U\+D\+P()}{closeUDP()}}
{\footnotesize\ttfamily void close\+U\+DP (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Close the U\+DP ports again to release network interfaces etc. If this is not done the network resources are still occupied and the program can\textquotesingle{}t exit properly. check if the socket is open and if yes close it Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=286pt]{main_8h_af2a8b7de0b15dc17198c147ba39e85f3_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_af2a8b7de0b15dc17198c147ba39e85f3_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a0416912fce6274568e80019b10ba294f}\label{main_8h_a0416912fce6274568e80019b10ba294f}} 
\index{main.\+h@{main.\+h}!determine\+Exposure@{determine\+Exposure}}
\index{determine\+Exposure@{determine\+Exposure}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{determine\+Exposure()}{determineExposure()}}
{\footnotesize\ttfamily int determine\+Exposure (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Get the optimal exposure for the camera. For that find the minimum and maximum exposure were the right number of markers are detected. Then the mean of those two values is used as exposure. For Opti\+Track Ethernet cameras, it\textquotesingle{}s important to enable development mode if you want to stop execution for an extended time while debugging without disconnecting the Ethernet devices. Lets do that now\+:

Initialize Camera S\+DK ==--

At this point the Camera S\+DK is actively looking for all connected cameras and will initialize them on it\textquotesingle{}s own.

Get a connected camera ================-\/---

If no device connected, pop a message box and exit ==--

Determine camera resolution to size application window ==-\/---

set the camera mode to precision mode, it used greyscale imformation for marker property calculations

Start camera output ==--

Turn on some overlay text so it\textquotesingle{}s clear things are ===--- working even if there is nothing in the camera\textquotesingle{}s view. ===---

set the camera exposure

set the camera infrared L\+ED intensity

set the camera framerate to 100 Hz

enable the filter that blocks visible light and only passes infrared light

enable high power mode of the leds

enable continuous L\+ED light

set threshold for marker detection

set exposure such that num markers are visible

Number of objects (markers) found in the current picture with the given exposure

exposure when objects detected the first time is number\+Markers

exposure when objects detected is first time number\+Markers+1

set the exposure to the smallest value possible

if the markers arent found after number\+Tries then there might be no markers at all in the real world

Determine minimum exposure, hence when are number\+Markers objects detected

get a new camera frame

frame received

how many objects are detected in the image

if the right amount if markers is found, exit while loop

not the right amount of markers was found so increase the exposure and try again

Now determine maximum exposure, hence when are number\+Markers+1 objects detected

if the markers arent found after number\+Tries then there might be no markers at all in the real world

how many objects are detected in the image

if the right amount if markers is found, exit while loop

not the right amount of markers was found so decrease the exposure and try again

set the exposure to the mean of min and max exposure determined

and now check if the correct amount of markers is detected with that new value

how many objects are detected in the image

are all markers and not more or less detected in the image

Release camera ==--

all markers and not more or less are found Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=327pt]{main_8h_a0416912fce6274568e80019b10ba294f_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a0416912fce6274568e80019b10ba294f_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a11ff459289305229597defd39f510959}\label{main_8h_a11ff459289305229597defd39f510959}} 
\index{main.\+h@{main.\+h}!determine\+Order@{determine\+Order}}
\index{determine\+Order@{determine\+Order}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{determine\+Order()}{determineOrder()}}
{\footnotesize\ttfamily void determine\+Order (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Compute the order of the marker points in 2D so they are the same as in the 3D array. Hence marker 1 must be in first place for both, list\+\_\+points2d and list\+\_\+points3d. determine the 3\+D-\/2D correspondences that are crucial for the PnP algorithm Try every possible correspondence and solve PnP Then project the 3D marker points into the 2D camera image and check the difference between projected points and points as seen by the camera the corresponce with the smallest difference is probably the correct one

the difference between true 2D points and projected points is super big

now try every possible permutation of correspondence

reset the starting values for solve\+PnP

sort the 2d points with the current permutation

Call solve P\+NP with P3P since its more robust and sufficient for start value determination

set the current difference of all point correspondences to zero

project the 3D points with the solve\+PnP solution onto 2D

now compute the absolute difference (error)

if the difference with the current permutation is smaller than the smallest value till now it is probably the more correct permutation

$<$ set the smallest value of difference to the current one

$<$ now safe the better permutation

try every permutation

now that the correct order is found assign it to the indices array Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a11ff459289305229597defd39f510959_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_af6430ad2592a955a3618549547dfc5be}\label{main_8h_af6430ad2592a955a3618549547dfc5be}} 
\index{main.\+h@{main.\+h}!draw\+Position\+Text@{draw\+Position\+Text}}
\index{draw\+Position\+Text@{draw\+Position\+Text}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{draw\+Position\+Text()}{drawPositionText()}}
{\footnotesize\ttfamily void draw\+Position\+Text (\begin{DoxyParamCaption}\item[{cv\+::\+Mat \&}]{Picture,  }\item[{cv\+::\+Vec3d \&}]{Position,  }\item[{cv\+::\+Vec3d \&}]{Euler,  }\item[{double}]{error }\end{DoxyParamCaption})}

Draw the position, attitude and reprojection error in the picture. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\tt in}  & {\em Picture} & is the camera image in Open\+CV matrix format. \\
\hline
\mbox{\tt in}  & {\em Position} & is the position of the tracked object in navigation Co\+Sy. \\
\hline
\mbox{\tt in}  & {\em Euler} & are the Euler angles with respect to the navigation frame. \\
\hline
\mbox{\tt in}  & {\em error} & is the reprojection error of the pose estimation. \\
\hline
\end{DoxyParams}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_af6430ad2592a955a3618549547dfc5be_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_ad39626702ff983d5fdab4b703bfaf964}\label{main_8h_ad39626702ff983d5fdab4b703bfaf964}} 
\index{main.\+h@{main.\+h}!load\+Calibration@{load\+Calibration}}
\index{load\+Calibration@{load\+Calibration}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{load\+Calibration()}{loadCalibration()}}
{\footnotesize\ttfamily void load\+Calibration (\begin{DoxyParamCaption}\item[{int}]{method }\end{DoxyParamCaption})}

Load a previously saved camera calibration from a file. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\tt in}  & {\em method} & whether or not load the camera calibration from calibration.\+xml. If ==0 then yes, if != 0 then let the user select a different file. \\
\hline
\end{DoxyParams}
Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=306pt]{main_8h_ad39626702ff983d5fdab4b703bfaf964_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_ad39626702ff983d5fdab4b703bfaf964_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_af39fa6c3a36ad6bc24a327db7a9d73c2}\label{main_8h_af39fa6c3a36ad6bc24a327db7a9d73c2}} 
\index{main.\+h@{main.\+h}!load\+Camera\+Position@{load\+Camera\+Position}}
\index{load\+Camera\+Position@{load\+Camera\+Position}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{load\+Camera\+Position()}{loadCameraPosition()}}
{\footnotesize\ttfamily void load\+Camera\+Position (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Load the rotation matrix from camera Co\+Sy to ground Co\+Sy It is determined during \hyperlink{main_8cpp_a7ad2e3cfb5056dbab2098e0dd3bd353f}{calibrate\+Ground()} and stays the same once the camera is mounted and fixed. Open the reference\+Data.\+xml that contains the rotation from camera Co\+Sy to ground Co\+Sy Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=330pt]{main_8h_af39fa6c3a36ad6bc24a327db7a9d73c2_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_af39fa6c3a36ad6bc24a327db7a9d73c2_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a56c7f641859cb2b6b99b0947d03be800}\label{main_8h_a56c7f641859cb2b6b99b0947d03be800}} 
\index{main.\+h@{main.\+h}!load\+Marker\+Config@{load\+Marker\+Config}}
\index{load\+Marker\+Config@{load\+Marker\+Config}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{load\+Marker\+Config()}{loadMarkerConfig()}}
{\footnotesize\ttfamily void load\+Marker\+Config (\begin{DoxyParamCaption}\item[{int}]{method }\end{DoxyParamCaption})}

Load a marker configuration from file. This file has to be created by hand, use the standard marker configuration file as template. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\tt in}  & {\em method} & whether or not load the configuration from the marker\+Standard.\+xml. If ==0 load it, if != 0 let the user select a different file. \\
\hline
\end{DoxyParams}
during start up of the programm load the standard marker configuration

open the standard marker configuration file

copy the values to the respective variables

inizialise vectors with correct length depending on the number of markers

save the marker locations in the points3d vector

if the load marker configuration button was clicked show a open file dialog

was cancel or abort clicked

if yes load the standard marker configuration

open the selected marker configuration file

copy the values to the respective variables

inizialise vectors with correct length depending on the number of markers

save the marker locations in the points3d vector

Print out the number of markers and their position to the G\+UI

check if P3P algorithm can be enabled, it needs exactly 4 marker points to work

if P3P is possible, let the user choose which algorithm he wants but keep iterative active

More (or less) marker than 4 loaded, P3P is not possible, hence user cant select P3P in G\+UI

now display the marker configuration in the camera view

Set the camera pose parallel to the marker coordinate system Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=344pt]{main_8h_a56c7f641859cb2b6b99b0947d03be800_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a56c7f641859cb2b6b99b0947d03be800_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a2104a5d9d6b9f1e29bc4cd858c59882e}\label{main_8h_a2104a5d9d6b9f1e29bc4cd858c59882e}} 
\index{main.\+h@{main.\+h}!project\+Coordinate\+Frame@{project\+Coordinate\+Frame}}
\index{project\+Coordinate\+Frame@{project\+Coordinate\+Frame}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{project\+Coordinate\+Frame()}{projectCoordinateFrame()}}
{\footnotesize\ttfamily void project\+Coordinate\+Frame (\begin{DoxyParamCaption}\item[{Mat}]{picture\+Frame }\end{DoxyParamCaption})}

Project the coordinate Co\+Sy origin and axis direction of the marker Co\+Sy with the rotation and translation of the object for visualization. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\tt in}  & {\em picture\+Frame} & the image in which the Co\+Sy frame should be pasted. \\
\hline
\end{DoxyParams}
$<$z-\/axis

$<$x-\/axis

$<$y-\/axis Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a2104a5d9d6b9f1e29bc4cd858c59882e_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a54b6b6db348b48d21e1265e22829c61f}\label{main_8h_a54b6b6db348b48d21e1265e22829c61f}} 
\index{main.\+h@{main.\+h}!send\+Data\+U\+DP@{send\+Data\+U\+DP}}
\index{send\+Data\+U\+DP@{send\+Data\+U\+DP}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{send\+Data\+U\+D\+P()}{sendDataUDP()}}
{\footnotesize\ttfamily void send\+Data\+U\+DP (\begin{DoxyParamCaption}\item[{cv\+::\+Vec3d \&}]{Position,  }\item[{cv\+::\+Vec3d \&}]{Euler }\end{DoxyParamCaption})}

Send the position and attitude over U\+DP to every receiver, the safety receiver is handled on its own in the start\+Tracking function because its send rate is less than 100 Hz. Roll Pitch Heading

if second receiver is activated send it also the tracking data Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a54b6b6db348b48d21e1265e22829c61f_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_ad19da4e648bbdc80d3123eb94711588e}\label{main_8h_ad19da4e648bbdc80d3123eb94711588e}} 
\index{main.\+h@{main.\+h}!set\+Heading\+Offset@{set\+Heading\+Offset}}
\index{set\+Heading\+Offset@{set\+Heading\+Offset}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{set\+Heading\+Offset()}{setHeadingOffset()}}
{\footnotesize\ttfamily void set\+Heading\+Offset (\begin{DoxyParamCaption}\item[{double}]{d }\end{DoxyParamCaption})}

Add a heading offset to the attitude for the case it is wanted by the user. 
\begin{DoxyParams}[1]{Parameters}
\mbox{\tt in}  & {\em d} & denotes heading offset in degrees. \\
\hline
\end{DoxyParams}
Convert heading offset from degrees to rad

Calculate rotation about x axis

Calculate rotation about y axis

Calculate rotation about z axis

Combined rotation matrix Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_ad19da4e648bbdc80d3123eb94711588e_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a1e6662e0f16887fe97c7bebe05065972}\label{main_8h_a1e6662e0f16887fe97c7bebe05065972}} 
\index{main.\+h@{main.\+h}!set\+Reference@{set\+Reference}}
\index{set\+Reference@{set\+Reference}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{set\+Reference()}{setReference()}}
{\footnotesize\ttfamily int set\+Reference (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Determine the initial position of the object that serves as reference point or as ground frame origin. Computes the pose 200 times and then averages it. The position and attitude are from now on used as navigation Co\+Sy. initialize the variables with starting values

Initialize Camera S\+DK ==--

At this point the Camera S\+DK is actively looking for all connected cameras and will initialize them on it\textquotesingle{}s own.

Get a connected camera ================-\/---

If no device connected, pop a message box and exit ==--

Determine camera resolution to size application window ==-\/---

Set camera mode to precision mode, it directly provides marker coordinates

Start camera output ==--

Turn on some overlay text so it\textquotesingle{}s clear things are ===--- working even if there is nothing in the camera\textquotesingle{}s view. ===--- Set some other parameters as well of the camera

sample some frames and calculate the position and attitude. then average those values and use that as zero position

$<$ difference between the marker points as seen by the camera and the projected marker points with Rvec and Tvec

Fetch a new frame from the camera ===---

Ok, we\textquotesingle{}ve received a new frame, lets do something with it.

for(int i=0; i$<$frame-\/$>$Object\+Count(); i++)

sort the 2d points with the correct indices as found in the preceeding order determination algorithm

Compute the pose from the 3\+D-\/2D corresponses

project the marker 3d points with the solution into the camera image Co\+Sy and calculate difference to true camera image

$<$Iterative Method needs time to converge to solution

$<$ That are not the values of yaw, roll and pitch yet! Rodriguez has to be called first.

$<$ one sample more \+:D

Release camera ==--

Divide by the number of samples to get the mean of the reference position

$<$ euler\+Ref is here in Axis Angle notation

$<$ axis angle to rotation matrix

-- Euler Angles, finally

$<$ rotation matrix to euler

compute the difference between last obtained T\+Vec and the average Value When it is large the iterative method has not converged properly so it is advised to start the \hyperlink{main_8cpp_a1e6662e0f16887fe97c7bebe05065972}{set\+Reference()} function once again Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a1e6662e0f16887fe97c7bebe05065972_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=306pt]{main_8h_a1e6662e0f16887fe97c7bebe05065972_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_ae624b0189bc5e32cbbb1f178b9f1a360}\label{main_8h_ae624b0189bc5e32cbbb1f178b9f1a360}} 
\index{main.\+h@{main.\+h}!set\+Up\+U\+DP@{set\+Up\+U\+DP}}
\index{set\+Up\+U\+DP@{set\+Up\+U\+DP}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{set\+Up\+U\+D\+P()}{setUpUDP()}}
{\footnotesize\ttfamily void set\+Up\+U\+DP (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Open the U\+DP ports for communication. 

Initialise the Q\+Data\+Stream that stores the data to be send

Create U\+DP slots

if the safety feature is activated open the udp port

if the second receiver feature is activated open the udp port Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=288pt]{main_8h_ae624b0189bc5e32cbbb1f178b9f1a360_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_ae624b0189bc5e32cbbb1f178b9f1a360_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a25183e8d0b386ef12b557efc712a0261}\label{main_8h_a25183e8d0b386ef12b557efc712a0261}} 
\index{main.\+h@{main.\+h}!start\+Stop\+Camera@{start\+Stop\+Camera}}
\index{start\+Stop\+Camera@{start\+Stop\+Camera}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{start\+Stop\+Camera()}{startStopCamera()}}
{\footnotesize\ttfamily void start\+Stop\+Camera (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Start or stop the tracking depending on if the camera is currently running or not. 

tracking is not running so start it

$<$ tracking is currently running, set exit\+Request to true so the while loop in \hyperlink{main_8cpp_a3d3afd29ce54eb7fc5cc7e74ab666586}{start\+Tracking()} exits Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a25183e8d0b386ef12b557efc712a0261_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a25183e8d0b386ef12b557efc712a0261_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a3d3afd29ce54eb7fc5cc7e74ab666586}\label{main_8h_a3d3afd29ce54eb7fc5cc7e74ab666586}} 
\index{main.\+h@{main.\+h}!start\+Tracking@{start\+Tracking}}
\index{start\+Tracking@{start\+Tracking}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{start\+Tracking()}{startTracking()}}
{\footnotesize\ttfamily int start\+Tracking (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Start the loop that fetches frames, computes the position etc and sends it to other computers. This function is the core of this program, hence the pose estimation is done here. The order of points, hence which entry in list\+\_\+points3d corresponds to which in list\+\_\+points2d is not calculated yet

Use the value of Rvec that was set in \hyperlink{main_8cpp_a0ddf1224851353fc92bfbff6f499fa97}{main()} as starting value for the solve\+PnP algorithm

Use the value of Tvec that was set in \hyperlink{main_8cpp_a0ddf1224851353fc92bfbff6f499fa97}{main()} as starting value for the solve\+PnP algorithm

Get the current date and time to name the log file

Concat the log file name as followed. The file is saved in the folder /logs in the Rigid Track installation folder

Convert the Q\+String to a standard string

Get the exposure where the right amount of markers is detected

For Opti\+Track Ethernet cameras, it\textquotesingle{}s important to enable development mode if you want to stop execution for an extended time while debugging without disconnecting the Ethernet devices. Lets do that now\+:

Initialize Camera S\+DK

At this point the Camera S\+DK is actively looking for all connected cameras and will initialize them on it\textquotesingle{}s own

Get a connected camera

If no camera can be found, inform user in message log and exit function

Determine camera resolution to size application window

Set the camera mode to precision mode, it used greyscale imformation for marker property calculations

Start camera output

Turn on some overlay text so it\textquotesingle{}s clear things are working even if there is nothing in the camera\textquotesingle{}s view

Set the camera exposure

Set the camera infrared L\+ED intensity

Set the camera framerate to 100 Hz

Enable the filter that blocks visible light and only passes infrared light

Enable high power mode of the L\+E\+Ds

Disable continuous L\+ED light

Set threshold for marker detection

Create a new matrix that stores the grayscale picture from the camera

Q\+Pixmap is the corresponding Qt class that saves images

Matrix that stores the colored picture, hence marker points, coordinate frame and reprojected points

Helper variable used to kick safety switch

Variables for the min and max values that are needed for sanity checks

Ff a marker is not visible or accuracy is bad increase this counter

Equals the quality of the tracking

Open sockets and ports for U\+DP communication

If the safety feature is enabled send the starting message

Send enable message, hence send a 9 and then a 1

Fetch a new frame from the camera

Get the timestamp of the first frame. This time is subtracted from every subseeding frame so the time starts at 0 in the logs

While no new frame is received loop

Get a new camera frame

There is actually a new frame

Get the time stamp for the first frame. It is subtracted for the following frames

Release the frame so the camera can continue

Exit the while loop

Now enter the main loop that processes each frame and computes the pose, sends it and logs stuff

Check if the user has not pressed \char`\"{}\+Stop Tracking\char`\"{} yet

Fetch a new frame from the camera

Did we got a new frame or does the camera still need more time

Increase by one, if everything is okay it is decreased at the end of the loop again

Only use this frame it the right number of markers is found in the picture

Get the marker points in 2D in the camera image frame and store them in the list\+\_\+points2d\+Unsorted vector The order of points that come from the camera corresponds to the Y coordinate

Was the order already determined? This is false for the first frame and from then on true

Now compute the order

Sort the 2d points with the correct indices as found in the preceeding order determination algorithm

point\+Order\+Indices was calculated in \hyperlink{main_8cpp_a11ff459289305229597defd39f510959}{determine\+Order()}

The first time the 2\+D-\/3D corresspondence was determined with got\+Order was okay. But this order can change as the object moves and the marker objects appear in a different order in the frame-\/$>$Object() array. The solution is that\+: When a marker point (in the camera image, hence in 2D) was at a position then it wont move that much from one frame to the other. So for the new frame we take a marker object and check which marker was closest this point in the old image frame? This is probably the same (true) marker. And we do that for every other marker as well. When tracking is good and no frames are dropped because of missing markers this should work every frame.

The sum of point distances is set to something unrealistic large

Calculate N\+\_\+2 norm of unsorted points minus old points

If the norm is smaller than min\+Point\+Distance the correspondence is more likely to be correct

Update the array that saves the new point order

Now the new order is found, set the point order to the new value

Save the unsorted position of the marker points for the next loop

Compute the object pose from the 3\+D-\/2D corresponses

Project the marker 3d points with the solution into the camera image Co\+Sy and calculate difference to true camera image

Difference of true pose and found pose

Increase the frames\+Dropped variable if accuracy of tracking is too bad

Set number of subsequent frames dropped to zero because error is small enough and no marker was missing

Get the min and max values from T\+Vec for sanity check

Sanity check of values. negative z means the marker Co\+Sy is behind the camera, that\textquotesingle{}s not possible.

Release the frame so the camera can move on

Release the camera

Close all U\+DP connections so the programm can be closed later on and no resources are locked

Exit the function

Next step is the transformation from camera Co\+Sy to navigation Co\+Sy Compute the relative object position from the reference position to the current one given in the camera Co\+Sy\+: $ T_C^{NM} = Tvec - Tvec_{Ref} $

Transform the position from the camera Co\+Sy to the navigation Co\+Sy with I\+NS alligned heading and convert from \mbox{[}mm\mbox{]} to \mbox{[}m\mbox{]} $ T_N^{NM} = M_{NC} \times T_C^{NM} $

Position is the result of the preceeding calculation

Invert Z if check box in G\+UI is activated, hence height above ground is considered

Realtive angle between reference orientation and current orientation

Convert axis angle respresentation to ordinary rotation matrix

The difference of the reference rotation and the current rotation $ R_{ NM } = M_{ NC } \times R_{ CM } $

Euler Angles, finally

Get the euler angles from the rotation matrix

Add the heading offset to the heading angle

Compute the velocity with finite differences. Only use is the log file. It is done here because the more precise time stamp can be used

Time between the old frame and the current frame

Set the old frame time to the current one

Calculate the x velocity with finite differences

Calculate the y velocity with finite differences

Calculate the z velocity with finite differences

Set the old position to the current one for next frame velocity calcuation

Send position and Euler angles over Wi\+Fi with 100 Hz

Save the values in a log file, values are\+: Time sinc tracking started Position Euler Angles Velocity

Open the log file, the folder is Rigid\+Track\+Installation\+Folder/logs

Close the file to save values

Check if the position and euler angles are below the allowed value, if yes send O\+K\+AY signal (1), if not send shutdown signal (0) Absolute x, y and z position in navigation Co\+Sy must be smaller than the allowed distance

Absolute Euler angles must be smaller than allowed value. Heading is not considered

Send the O\+K\+AY signal to the desired computer every 5th time

Send the 1

reset the counter that is needed for decimation to every 5th time step

The euler angles of the object exceeded the allowed euler angles, send the shutdown signal (0)

Send the shutdown signal, a 0

Inform the user

The position of the object exceeded the allowed position, shut the object down

Send the shutdown signal, a 0

Inform the user

Inform the user if tracking system is disturbed (marker lost or so) or error was too big

Also send the shutdown signal

Send the shutdown signal, a 0

Inform the user

Rasterize the frame so it can be shown in the G\+UI

Convert the frame from greyscale as it comes from the camera to rgb color

Project (draw) the marker Co\+Sy origin into 2D and save it in the c\+Frame image

Project the marker points from 3D to the camera image frame (2d) with the computed pose

Draw a circle around the projected points so the result can be better compared to the real marker position In the resulting picture those are the red dots

Write the current position, attitude and error values as text in the frame

Send the new camera picture to the G\+UI and call the G\+UI processing routine

Update the picture in the G\+UI

Give Qt time to handle everything

Release the camera frame to fetch the new one

User choose to stop the tracking, clean things up

Close the U\+DP connections so resources are deallocated

Release camera Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a3d3afd29ce54eb7fc5cc7e74ab666586_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a3d3afd29ce54eb7fc5cc7e74ab666586_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{main_8h_a847c0fbd3e513fb76ff145b31a9f5c37}\label{main_8h_a847c0fbd3e513fb76ff145b31a9f5c37}} 
\index{main.\+h@{main.\+h}!test\+Algorithms@{test\+Algorithms}}
\index{test\+Algorithms@{test\+Algorithms}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{test\+Algorithms()}{testAlgorithms()}}
{\footnotesize\ttfamily void test\+Algorithms (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Project some points from 3D to 2D and then check the accuracy of the algorithms. Mainly to generate something that can be shown in the camera view so the user knows everything loaded correctly. $<$ in mm

$<$ 0 = iterative 1 = E\+P\+NP 2 = P3P 4 = U\+P\+NP //!$<$ not used

$<$ 0 = iterative 1 = E\+P\+NP 2 = P3P 4 = U\+P\+NP U\+PnP not used

$<$ 0 = iterative 1 = E\+P\+NP 2 = P3P 4 = U\+P\+NP //!$<$ not used

$<$ 0 = iterative 1 = E\+P\+NP 2 = P3P 4 = U\+P\+NP //!$<$ not used Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=332pt]{main_8h_a847c0fbd3e513fb76ff145b31a9f5c37_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{main_8h_a847c0fbd3e513fb76ff145b31a9f5c37_icgraph}
\end{center}
\end{figure}


\subsection{Variable Documentation}
\mbox{\Hypertarget{main_8h_af29e7fc07ae0979d5fb61b473241d33d}\label{main_8h_af29e7fc07ae0979d5fb61b473241d33d}} 
\index{main.\+h@{main.\+h}!comm\+Obj@{comm\+Obj}}
\index{comm\+Obj@{comm\+Obj}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{comm\+Obj}{commObj}}
{\footnotesize\ttfamily \hyperlink{classcomm_object}{comm\+Object} comm\+Obj}



class that handles the communication from \hyperlink{main_8cpp}{main.\+cpp} to the G\+UI 

Now declare variables that are used across the \hyperlink{main_8cpp}{main.\+cpp} file. Basically almost every variable used is declared here. \mbox{\Hypertarget{main_8h_a5cc3bd09f5801804b7ae65846e0b9824}\label{main_8h_a5cc3bd09f5801804b7ae65846e0b9824}} 
\index{main.\+h@{main.\+h}!invertZ@{invertZ}}
\index{invertZ@{invertZ}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{invertZ}{invertZ}}
{\footnotesize\ttfamily int invertZ}



dummy variable to invert Z direction on request 

\mbox{\Hypertarget{main_8h_ab97ac0d82b1753d0eef37089be17e5e1}\label{main_8h_ab97ac0d82b1753d0eef37089be17e5e1}} 
\index{main.\+h@{main.\+h}!I\+P\+Adress\+Object@{I\+P\+Adress\+Object}}
\index{I\+P\+Adress\+Object@{I\+P\+Adress\+Object}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{I\+P\+Adress\+Object}{IPAdressObject}}
{\footnotesize\ttfamily Q\+Host\+Address I\+P\+Adress\+Object}



I\+Pv4 adress of receiver 1. 

\mbox{\Hypertarget{main_8h_afefb1102a8a4a71b55d6f24f46404cc5}\label{main_8h_afefb1102a8a4a71b55d6f24f46404cc5}} 
\index{main.\+h@{main.\+h}!I\+P\+Adress\+Safety@{I\+P\+Adress\+Safety}}
\index{I\+P\+Adress\+Safety@{I\+P\+Adress\+Safety}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{I\+P\+Adress\+Safety}{IPAdressSafety}}
{\footnotesize\ttfamily Q\+Host\+Address I\+P\+Adress\+Safety}



I\+Pv4 adress of safety receiver. 

\mbox{\Hypertarget{main_8h_a354806cf8cbface3575f2541d8fbcbda}\label{main_8h_a354806cf8cbface3575f2541d8fbcbda}} 
\index{main.\+h@{main.\+h}!I\+P\+Adress\+Safety2@{I\+P\+Adress\+Safety2}}
\index{I\+P\+Adress\+Safety2@{I\+P\+Adress\+Safety2}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{I\+P\+Adress\+Safety2}{IPAdressSafety2}}
{\footnotesize\ttfamily Q\+Host\+Address I\+P\+Adress\+Safety2}



I\+Pv4 adress of receiver 2. 

\mbox{\Hypertarget{main_8h_ab5e634b66221f494504aea1557af5df9}\label{main_8h_ab5e634b66221f494504aea1557af5df9}} 
\index{main.\+h@{main.\+h}!method\+P\+NP@{method\+P\+NP}}
\index{method\+P\+NP@{method\+P\+NP}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{method\+P\+NP}{methodPNP}}
{\footnotesize\ttfamily int method\+P\+NP}



solve\+P\+NP algorithm 0 = iterative 1 = E\+P\+NP 2 = P3P 4 = U\+P\+NP //!$<$ 4 and 1 are the same and not implemented correctly by Open\+CV 

\mbox{\Hypertarget{main_8h_a9a00043c93a3362969c1c1fcd3a70fea}\label{main_8h_a9a00043c93a3362969c1c1fcd3a70fea}} 
\index{main.\+h@{main.\+h}!port\+Object@{port\+Object}}
\index{port\+Object@{port\+Object}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{port\+Object}{portObject}}
{\footnotesize\ttfamily int port\+Object}



Port of receiver 1. 

\mbox{\Hypertarget{main_8h_a137bc8cc9d53ad9b176c988a99bc7142}\label{main_8h_a137bc8cc9d53ad9b176c988a99bc7142}} 
\index{main.\+h@{main.\+h}!port\+Safety@{port\+Safety}}
\index{port\+Safety@{port\+Safety}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{port\+Safety}{portSafety}}
{\footnotesize\ttfamily int port\+Safety}



Port of the safety receiver. 

\mbox{\Hypertarget{main_8h_a2601be9c226be24c71ec8282f632e723}\label{main_8h_a2601be9c226be24c71ec8282f632e723}} 
\index{main.\+h@{main.\+h}!port\+Safety2@{port\+Safety2}}
\index{port\+Safety2@{port\+Safety2}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{port\+Safety2}{portSafety2}}
{\footnotesize\ttfamily int port\+Safety2}



Port of receiver 2. 

\mbox{\Hypertarget{main_8h_a436fb814ccc3f02617dade4dc6511143}\label{main_8h_a436fb814ccc3f02617dade4dc6511143}} 
\index{main.\+h@{main.\+h}!safety2\+Enable@{safety2\+Enable}}
\index{safety2\+Enable@{safety2\+Enable}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{safety2\+Enable}{safety2Enable}}
{\footnotesize\ttfamily bool safety2\+Enable}



is the second receiver enabled 

\mbox{\Hypertarget{main_8h_ae65386c3310ab826e84fba757296de9a}\label{main_8h_ae65386c3310ab826e84fba757296de9a}} 
\index{main.\+h@{main.\+h}!safety\+Angle@{safety\+Angle}}
\index{safety\+Angle@{safety\+Angle}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{safety\+Angle}{safetyAngle}}
{\footnotesize\ttfamily int safety\+Angle}



bank and pitch angle protection in degrees 

\mbox{\Hypertarget{main_8h_a2c1b807fcb2de5a6759bd60ccae6dd7e}\label{main_8h_a2c1b807fcb2de5a6759bd60ccae6dd7e}} 
\index{main.\+h@{main.\+h}!safety\+Box\+Length@{safety\+Box\+Length}}
\index{safety\+Box\+Length@{safety\+Box\+Length}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{safety\+Box\+Length}{safetyBoxLength}}
{\footnotesize\ttfamily double safety\+Box\+Length}



length of the safety area cube in meters 

\mbox{\Hypertarget{main_8h_aa6266eedab8b3c011be53baffbfc42ab}\label{main_8h_aa6266eedab8b3c011be53baffbfc42ab}} 
\index{main.\+h@{main.\+h}!safety\+Enable@{safety\+Enable}}
\index{safety\+Enable@{safety\+Enable}!main.\+h@{main.\+h}}
\subsubsection{\texorpdfstring{safety\+Enable}{safetyEnable}}
{\footnotesize\ttfamily bool safety\+Enable}



is the safety feature enabled 

